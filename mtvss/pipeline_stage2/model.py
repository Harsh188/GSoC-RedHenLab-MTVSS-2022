# Copyright (c) 2022 Harshith Mohan Kumar

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# =============================================================================

# Imports
import glob
import os
import sys
import numpy as np
import time

from sklearn.neighbors import KNeighborsTransformer

from sklearn.datasets import fetch_openml
from sklearn import metrics

sys.path.append(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))

import constants as const

class Model:
	'''
	'''

	def __init__(self,verbose,file_path,run_on_mnt):
		'''
		'''
		self.verbose=verbose
		self.file_path=file_path

		if(not run_on_mnt):
			sys.path.insert(1,self.file_path+'/sklearn_ann/cluster')
		else:
			sys.path.insert(1,const.H_PROJ_PATH+'sklearn_ann/cluster')

		self.RnnDBSCAN = __import__('rnn_dbscan')

	def run_rnn_dbscan(self,data):
		'''This method is used to run the clustering algorithm on the stage-1 metadata.
		Args:
			data (np.mmap): Cleaned features extracted from stage-1.
		Returns:
			N/A
		'''
		n_neighbors = [2,3,4,5]
		for n in n_neighbors:
			start_time = time.time()
			if self.verbose:
				print('\n### Optimization Step')
				print('\n### n_neighbors:',n)

			pipeline = self.RnnDBSCAN.simple_rnn_dbscan_pipeline(KNeighborsTransformer, n)
			labels = pipeline.fit_predict(data)
			db = pipeline.named_steps["rnndbscan"]
			core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
			core_samples_mask[db.core_sample_indices_] = True
			delta_time = (time.time() - start_time)
			self.evaluate_rnn_dbscan(labels,data,delta_time,n)

	def evaluate_rnn_dbscan(self,labels,data,delta_time,n_neigh):
		'''This method evaluates the rnn dbscan using silhouette coefficient
			and measuring the amount of points in each cluster.
		Args:
			labels (np.ndarray): Labels generated by clustering.
			data (np.mmap): Cleaned features extracted from stage-1.
			delta_time (str): The number of seconds which has taken to execute RRN-DBSCAN.
			n_neigh (int): The number of N neighbors used in RNN-DBSCAN
		Returns:
			N/A
		'''
		# Number of clusters in labels, ignoring noise if present.
		n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
		n_noise_ = list(labels).count(-1)
		unique, counts = np.unique(labels, return_counts=True) 
		label_counts = np.column_stack((unique,counts))

		if self.verbose:
			print('Estimated number of clusters: %d' % n_clusters_)
			print('Estimated number of noise points: %d' % n_noise_)
			print('Estimated cluster counts:',label_counts)
			print("Silhouette Coefficient: %0.3f"
			      % metrics.silhouette_score(data, labels))
			print('Time taken (sec): %s' % delta_time)

		np.save(const.H_GAL_HOME_PATH+'splits/phase-2-'+str(n_neigh)+'_outputs.npy',labels)
		